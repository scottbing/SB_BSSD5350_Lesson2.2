{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cubic-equipment",
   "metadata": {},
   "source": [
    "# SSB_5350_Perceptron2.2 \n",
    "### Scott Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adult-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collaborative-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-sessions",
   "metadata": {},
   "source": [
    "# Define the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "governmental-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights(w, act):\n",
    "    err = 0\n",
    "    for i in range(len(piv)):\n",
    "       vs = weighted_sum(piv[i], w[1:]) + weights[0]\n",
    "       if act(vs, threshold) != labels[i]:\n",
    "           err+=1\n",
    "    print(err/len(piv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "earned-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(cycles):\n",
    "    step =  2.0\n",
    "    for c in range(cycles):\n",
    "        #initialize error to 0 for each cycle\n",
    "        num_errors = 0\n",
    "        \n",
    "        for  i in range(len(piv)):\n",
    "            w_sum = weighted_sum(piv[i], weights[1:])\n",
    "            #add bias whdi is first weight\n",
    "            w_sum = weights[0] + w_sum\n",
    "            act = activation(w_sum, threshold)\n",
    "            #determine if the weights yeild right answers\n",
    "            # if so then erro 0 or no error\n",
    "            error = labels[i] - act\n",
    "            \n",
    "            if error != 0:\n",
    "                #increase error count\n",
    "                num_errors += 1\n",
    "#update weights to minimize error in  next cycle\n",
    "                #update weights to minimize error in next cycle\n",
    "                weights[0] += step * error * piv[i][0]\n",
    "                weights[1] += step * error * piv[i][1]\n",
    "#update bias\n",
    "                weights[0] += error\n",
    "        #end fit early if a cycle had no errors\n",
    "        print(c, num_errors)\n",
    "                \n",
    "        if num_errors == 0:\n",
    "            print(c, weights, bias)\n",
    "            break\n",
    "    else:\n",
    "        print(\"no answer found\")\n",
    "    return num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cordless-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(vec, weights):\n",
    "    w_vec = vec*weights;\n",
    "    return w_vec.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bibliographic-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(val, threshold):\n",
    "    if val >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-dover",
   "metadata": {},
   "source": [
    "# The Perceptron Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classical-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "precise_input_vals = np.array([[.4,.4], [.47,.8], [1.2,.49], [1.1, .8]])\n",
    "labels = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some random precise data\n",
    "precise_labels = []\n",
    "precise_rounds = []\n",
    "for i in range(20000):\n",
    "    large_donut = [random.uniform(2.5, 3.0), random.uniform(2.0, 3.0)]\n",
    "    donut       = [random.uniform(1.5, 2.0), random.uniform(1.0, 2.0)]\n",
    "    small_bagel = [random.uniform(0.0, 0.7), random.uniform(0.0, 0.5)]\n",
    "    reg_bagel   = [random.uniform(0.7, 1.5), random.uniform(0.5, 1.0)]\n",
    "    precise_rounds += [large_donut, donut, small_bagel, reg_bagel]\n",
    "    precise_labels += [1,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "democratic-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data                               \n",
    "ratio = int(len(precise_rounds)*.7)           \n",
    "train_piv = np.array(precise_rounds[:ratio])   \n",
    "train_labels = np.array(precise_labels[:ratio])\n",
    "                                            \n",
    "test_piv = np.array(precise_rounds[ratio:])   \n",
    "test_labels = np.array(precise_labels[ratio:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 211\n",
      "1 61\n",
      "2 180\n",
      "3 159\n",
      "4 0\n",
      "4 [-3.42398650e+02  2.29573487e+02  2.95520607e-02] -0.6675011977196244\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "piv = train_piv\n",
    "labels = train_labels\n",
    "bias = random.uniform(-1.0,1.0)\n",
    "#add bias on the end. Some people add bias on the beginning.\n",
    "weights = np.array([bias, random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "lifecycles = 20\n",
    "errors = fit(lifecycles)\n",
    "#must activate weighted test values to turn the back to lables 0 or 1\n",
    "piv = test_piv\n",
    "labels = test_labels\n",
    "test_weights(weights, activation) #passing activation funtion as param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impossible-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(p,l,s):\n",
    "    # Define the input\n",
    "    precise_input_vals = p\n",
    "    labels = l\n",
    "    #make some random precise data\n",
    "    precise_labels = []\n",
    "    precise_rounds = []\n",
    "    for i in range(s):\n",
    "        large_donut = [random.uniform(2.5, 3.0), random.uniform(2.0, 3.0)]\n",
    "        donut       = [random.uniform(1.5, 2.0), random.uniform(1.0, 2.0)]\n",
    "        small_bagel = [random.uniform(0.0, 0.7), random.uniform(0.0, 0.5)]\n",
    "        reg_bagel   = [random.uniform(0.7, 1.5), random.uniform(0.5, 1.0)]\n",
    "        precise_rounds += [large_donut, donut, small_bagel, reg_bagel]\n",
    "        precise_labels += [1,1,0,0]\n",
    "\n",
    "    #split the data                               \n",
    "    ratio = int(len(precise_rounds)*.7)           \n",
    "    train_piv = np.array(precise_rounds[:ratio])   \n",
    "    train_labels = np.array(precise_labels[:ratio])\n",
    "\n",
    "    test_piv = np.array(precise_rounds[ratio:])   \n",
    "    test_labels = np.array(precise_labels[ratio:])\n",
    "\n",
    "    piv = train_piv\n",
    "    labels = train_labels\n",
    "    bias = random.uniform(-1.0,1.0)\n",
    "    #add bias on the end. Some people add bias on the beginning.\n",
    "    weights = np.array([bias, random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "    threshold = 2.0\n",
    "    lifecycles = 20\n",
    "    errors = fit(lifecycles)\n",
    "    #must activate weighted test values to turn the back to lables 0 or 1\n",
    "    piv = test_piv\n",
    "    labels = test_labels\n",
    "    test_weights(weights, activation) #passing activation funtion as param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stock-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivs =  [-0.50002309  0.85310432]\n",
      "0 0\n",
      "0 [-3.42398650e+02  2.29573487e+02  2.95520607e-02] -0.6675011977196244\n",
      "0.5\n",
      "pivs =  [ 0.99523056 -0.4025329 ]\n",
      "0 0\n",
      "0 [-3.42398650e+02  2.29573487e+02  2.95520607e-02] -0.6675011977196244\n",
      "0.5\n",
      "pivs =  [ 0.86182881 -0.75446754]\n",
      "0 0\n",
      "0 [-3.42398650e+02  2.29573487e+02  2.95520607e-02] -0.6675011977196244\n",
      "0.5\n",
      "pivs =  [-0.56968875 -0.1914801 ]\n",
      "0 0\n",
      "0 [-3.42398650e+02  2.29573487e+02  2.95520607e-02] -0.6675011977196244\n",
      "0.5\n",
      "pivs =  [-0.50292747 -0.27815772]\n",
      "0 0\n",
      "0 [-3.42398650e+02  2.29573487e+02  2.95520607e-02] -0.6675011977196244\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "iter = 5\n",
    "for _ in range(iter):\n",
    "    pivs = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "    print(\"pivs = \", pivs)                \n",
    "    lbls = np.array([0, 0, 0, 1])\n",
    "    size = 20000\n",
    "    perceptron(pivs,lbls,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-hometown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
