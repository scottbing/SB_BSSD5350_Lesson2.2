{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optimum-caution",
   "metadata": {},
   "source": [
    "### Perceptron - Lab 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-civilization",
   "metadata": {},
   "source": [
    "### donuts vs Bagels\n",
    "- inputs [shininess, hole size]\n",
    "    - shiny = 1\n",
    "    - large hole = 1\n",
    "- labels\n",
    "    - 1 - donut\n",
    "    - 2 = bagel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hawaiian-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "italian-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 sets of input\n",
    "input_vals = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "#one label for each set (only one donut labled below)\n",
    "labels = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dense-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_vals)):\n",
    "    #turn each vector of features inot a single value\n",
    "    vs = input_vals[i].sum() #numpy vector sum operation\n",
    "    #check if single summed value equals the label\n",
    "    print(vs == labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lyric-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#apply weights to dtermine how important one feature is over another\n",
    "weights = np.array([1,2]) #hole more imporatnt than shine\n",
    "for i in range(len(input_vals)):\n",
    "    w_vec = input_vals[i] * weights\n",
    "    vs = w_vec.sum()\n",
    "    #check if single summed value equals the label\n",
    "    print(vs == labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lonely-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "2 0\n",
      "1 0\n",
      "3 1\n"
     ]
    }
   ],
   "source": [
    "#apply weights to dtermine how important one feature is over another\n",
    "weights = np.array([1,2]) #hole more imporatnt than shine\n",
    "for i in range(len(input_vals)):\n",
    "    w_vec = input_vals[i] * weights\n",
    "    vs = w_vec.sum()\n",
    "    #check if single summed value equals the label\n",
    "    print(vs, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grave-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(vec, weights):\n",
    "    w_vec = vec*weights;\n",
    "    return w_vec.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stainless-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(val, threshold):\n",
    "    if val >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiac-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([1,2]) #hole more imporatnt than shine\n",
    "\n",
    "for i in range(len(input_vals)):\n",
    "    ws = weighted_sum(input_vals[i], weights)\n",
    "    threshold = 3\n",
    "    print(activation(ws,threshold) == labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blocked-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "precise_input_vals = np.array([[.4,.4], [.47,.8], [1.2,.49], [1.1, .8]])\n",
    "labels = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "actual-bowling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2000000000000002 0\n",
      "2.0700000000000003 0\n",
      "2.1799999999999997 0\n",
      "2.7 1\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([1,2]) #hole more imporatnt than shine\n",
    "\n",
    "for i in range(len(precise_input_vals)):\n",
    "    ws = weighted_sum(precise_input_vals[i], weights)\n",
    "    threshold = 3\n",
    "    print(ws, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "damaged-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.2000000000000002 0\n",
      "True\n",
      "2.0700000000000003 0\n",
      "True\n",
      "2.1799999999999997 0\n",
      "False\n",
      "2.7 1\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([1,2]) #hole more imporatnt than shine\n",
    "\n",
    "for i in range(len(precise_input_vals)):\n",
    "    ws = weighted_sum(precise_input_vals[i], weights)\n",
    "    threshold = 3\n",
    "    print(activation(ws,threshold) == labels[i])\n",
    "    print(ws, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "related-population",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.56 0\n",
      "True\n",
      "0.988 0\n",
      "True\n",
      "0.97 0\n",
      "False\n",
      "1.2400000000000002 1\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([0.4,1]) #hole more imporatnt than shine\n",
    "\n",
    "for i in range(len(precise_input_vals)):\n",
    "    ws = weighted_sum(precise_input_vals[i], weights)\n",
    "    threshold = 3\n",
    "    print(activation(ws,threshold) == labels[i])\n",
    "    print(ws, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "independent-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.16 0\n",
      "False\n",
      "4.188 0\n",
      "True\n",
      "2.93 0\n",
      "True\n",
      "4.44 1\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([0.4,5]) #hole more imporatnt than shine\n",
    "\n",
    "for i in range(len(precise_input_vals)):\n",
    "    ws = weighted_sum(precise_input_vals[i], weights)\n",
    "    threshold = 3\n",
    "    print(activation(ws,threshold) == labels[i])\n",
    "    print(ws, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amateur-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.4400000000000004 0\n",
      "True\n",
      "2.7480000000000007 0\n",
      "True\n",
      "2.048 0\n",
      "True\n",
      "3.0000000000000004 1\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([0.4,3.2]) #hole more imporatnt than shine\n",
    "\n",
    "for i in range(len(precise_input_vals)):\n",
    "    ws = weighted_sum(precise_input_vals[i], weights)\n",
    "    threshold = 3\n",
    "    print(activation(ws,threshold) == labels[i])\n",
    "    print(ws, labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-effectiveness",
   "metadata": {},
   "source": [
    "## Perceptron Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "protecting-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random #used to generate random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "composite-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = np.array([[.4,.4], [.47,.8], [1.2,.49], [1.1, .8]])\n",
    "labels = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fixed-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44569396  0.50380884]\n"
     ]
    }
   ],
   "source": [
    "weights = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "central-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit():\n",
    "    for i in range(len(piv)):\n",
    "        w_sum = weighted_sum(piv[i], weights)\n",
    "        act = activation(w_sum, threshold)\n",
    "        print(act, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extra-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "phantom-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(cycles):\n",
    "    step = 0.1\n",
    "    for c in range(cycles): \n",
    "        weights[0] += step \n",
    "        weights[1] += step \n",
    "        print(c, weights)\n",
    "        \n",
    "        for i in range(len(piv)):\n",
    "            w_sum = weighted_sum(piv[i], weights)     \n",
    "            act = activation(w_sum, threshold) \n",
    "            print(act, labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "uniform-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.34569396  0.60380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 [-0.24569396  0.70380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "2 [-0.14569396  0.80380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "3 [-0.04569396  0.90380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "4 [0.05430604 1.00380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "5 [0.15430604 1.10380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "6 [0.25430604 1.20380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "7 [0.35430604 1.30380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "8 [0.45430604 1.40380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "9 [0.55430604 1.50380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "10 [0.65430604 1.60380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "11 [0.75430604 1.70380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "12 [0.85430604 1.80380884]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "13 [0.95430604 1.90380884]\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "14 [1.05430604 2.00380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "15 [1.15430604 2.10380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "16 [1.25430604 2.20380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "17 [1.35430604 2.30380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "18 [1.45430604 2.40380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "19 [1.55430604 2.50380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "lifecycles = 20\n",
    "fit(lifecycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "brazilian-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.65430604 2.60380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 [1.75430604 2.70380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "2 [1.85430604 2.80380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "3 [1.95430604 2.90380884]\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "4 [2.05430604 3.00380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "5 [2.15430604 3.10380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "6 [2.25430604 3.20380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "7 [2.35430604 3.30380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "8 [2.45430604 3.40380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "9 [2.55430604 3.50380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "10 [2.65430604 3.60380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "11 [2.75430604 3.70380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "12 [2.85430604 3.80380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "13 [2.95430604 3.90380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "14 [3.05430604 4.00380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "15 [3.15430604 4.10380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "16 [3.25430604 4.20380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "17 [3.35430604 4.30380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "18 [3.45430604 4.40380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "19 [3.55430604 4.50380884]\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "lifecycles = 20\n",
    "fit(lifecycles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-frontier",
   "metadata": {},
   "source": [
    "# Perceptron Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pending-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  #used to generate random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "social-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = np.array([[.4,.4], [.47,.8], [1.2,.49], [1.1, .8]])\n",
    "labels = np.array([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "political-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(cycles):\n",
    "    step = 0.1\n",
    "    for c in range(cycles):\n",
    "        #intialize error to 0 for each cycle \n",
    "        num_errors = 0\n",
    "        \n",
    "        for i in range(len(piv)):\n",
    "            w_sum = weighted_sum(piv[i], weights)\n",
    "            act = activation(w_sum, threshold)\n",
    "            #determine if the weights yield right answers \n",
    "            # if so then error 0 or no error\n",
    "            error = labels[i] - act\n",
    "            \n",
    "            #if there was an error\n",
    "            if error != 0:\n",
    "                #increase error count\n",
    "                num_errors += 1\n",
    "                #update weights to minimize error in next cycle       \n",
    "                weights[0] += step * error * piv[i][0] \n",
    "                weights[1] += step * error * piv[i][1]\n",
    "                \n",
    "        #end fit early if a cycle had no errors\n",
    "        print(c, num_errors)\n",
    "        \n",
    "        if num_errors == 0:\n",
    "            print(c, weights) \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "increased-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "3 1\n",
      "4 1\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 2\n",
      "9 2\n",
      "10 2\n",
      "11 2\n",
      "12 2\n",
      "13 2\n"
     ]
    }
   ],
   "source": [
    "#initialize random weights between -1 and 1\n",
    "weights = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "lifecycles = 14\n",
    "fit(lifecycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sound-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(cycles):\n",
    "    step =  0.1\n",
    "    for c in range(cycles):\n",
    "        #initialize error to 0 for each cycle\n",
    "        num_errors = 0\n",
    "        \n",
    "        for  i in range(len(piv)):\n",
    "            w_sum = weighted_sum(piv[i], weights)\n",
    "            act = activation(w_sum, threshold)\n",
    "            #determine if the weights yeild right answers\n",
    "            # if so then erro 0 or no error\n",
    "            error = labels[i] - act\n",
    "            \n",
    "            if error != 0:\n",
    "                #increase error count\n",
    "                num_errors += 1\n",
    "                #update weights to minimize error in next cycle\n",
    "                weights[0] += step * error * piv[i][0]\n",
    "                weights[1] += step * error * piv[i][1]\n",
    "        if num_errors == 0:\n",
    "            print(c, weights)\n",
    "            break\n",
    "    else:\n",
    "        print(\"no answer found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thrown-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights(w, act):\n",
    "    for i in range(len(piv)):\n",
    "        vs = weighted_sum(piv[i], w)\n",
    "        print(act(vs, threshold), labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "knowing-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [1.08963568 1.07377665]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "#initialize random weights between -1 and 1\n",
    "weights = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "lifecycles = 14\n",
    "fit(lifecycles)\n",
    "#must acivate weighted test values to turn back to lables 0 or 1\n",
    "test_weights(weights, activation) #passign activation funtion as param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-suspect",
   "metadata": {},
   "source": [
    "### Split the data so you have some to train the weights on and some to test the calcualted weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-memphis",
   "metadata": {},
   "source": [
    "Take 70% pf the data o train awith and keep 30% to test with.\n",
    "_Sometimes you will see 60-20-20 split for train-test-validate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bridal-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some random precise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "painful-canvas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [0.98614601 1.32201157]\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "#initialize random weights between -1 and 1\n",
    "weights = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "lifecycles = 14\n",
    "fit(lifecycles)\n",
    "#must acivate weighted test values to turn back to lables 0 or 1\n",
    "test_weights(weights, activation) #passign activation funtion as param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "northern-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some random precise data\n",
    "precise_labels = []\n",
    "precise_rounds = []\n",
    "for i in range(100):\n",
    "    donut       = [random.uniform(1.0, 2.0), random.uniform(1.0, 2.0)]\n",
    "    small_bagel = [random.uniform(0.0, 0.5), random.uniform(0.0, 0.5)]\n",
    "    reg_bagel   = [random.uniform(0.5, 1.0), random.uniform(0.5, 1.0)]\n",
    "    precise_rounds += [donut, small_bagel, reg_bagel]\n",
    "    precise_labels += [1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "endangered-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-northwest",
   "metadata": {},
   "source": [
    "### Intoducing Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "facial-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "ratio = int(len(precise_rounds)*.7)\n",
    "train_piv = np.array(precise_rounds[:ratio])\n",
    "train_labels = np.array(precise_labels[:ratio])\n",
    "\n",
    "test_piv = np.array(precise_rounds[ratio:])\n",
    "test_labels = np.array(precise_labels[ratio:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "specialized-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [1.03461647 0.8548932 ]\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "piv = train_piv\n",
    "labels = train_labels\n",
    "weights = np.array([random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "lifecycles = 100\n",
    "fit(lifecycles)\n",
    "\n",
    "\n",
    "#must activate weighted test values to turn the back to lables 0 or 1\n",
    "piv = test_piv\n",
    "labels = test_labels\n",
    "test_weights(weights, activation) #passing activation funtion as param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "green-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(cycles):\n",
    "    step =  2.0\n",
    "    for c in range(cycles):\n",
    "        #initialize error to 0 for each cycle\n",
    "        num_errors = 0\n",
    "        \n",
    "        for  i in range(len(piv)):\n",
    "            w_sum = weighted_sum(piv[i], weights[1:])\n",
    "            #add bias whdi is first weight\n",
    "            w_sum = weights[0] + w_sum\n",
    "            act = activation(w_sum, threshold)\n",
    "            #determine if the weights yeild right answers\n",
    "            # if so then erro 0 or no error\n",
    "            error = labels[i] - act\n",
    "            \n",
    "            if error != 0:\n",
    "                #increase error count\n",
    "                num_errors += 1\n",
    "#update weights to minimize error in  next cycle\n",
    "                #update weights to minimize error in next cycle\n",
    "                weights[0] += step * error * piv[i][0]\n",
    "                weights[1] += step * error * piv[i][1]\n",
    "#update bias\n",
    "                weights[0] += error\n",
    "        #end fit early if a cycle had no errors\n",
    "        print(c, num_errors)\n",
    "                \n",
    "        if num_errors == 0:\n",
    "            print(c, weights, bias)\n",
    "            break\n",
    "    else:\n",
    "        print(\"no answer found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "promotional-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights(w, act):\n",
    "    err = 0\n",
    "    for i in range(len(piv)):\n",
    "       vs = weighted_sum(piv[i], w[1:]) + weights[0]\n",
    "       if act(vs, threshold) != labels[i]:\n",
    "           err+=1\n",
    "    print(err/len(piv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "scheduled-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "1 0\n",
      "1 [0.24833134 1.37951827 0.43436495] 0.6526723140770065\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "piv = train_piv\n",
    "labels = train_labels\n",
    "bias = random.uniform(-1.0,1.0)\n",
    "#add bias on the end. Some people add bias on the beginning.\n",
    "weights = np.array([bias, random.uniform(-1.0, 1.0), random.uniform(-1.0, 1.0)])\n",
    "threshold = 2.0\n",
    "lifecycles = 20\n",
    "fit(lifecycles)\n",
    "#must activate weighted test values to turn the back to lables 0 or 1\n",
    "piv = test_piv\n",
    "labels = test_labels\n",
    "test_weights(weights, activation) #passing activation funtion as param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-contractor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
